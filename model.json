[
  {
    id: "dall-e-2",
    name: "DALL·E 2",
    family: "image",
    desc: "OpenAI's powerful text-to-image model.",
    params: [
      {
        name: "n",
        label: "Count",
        type: "integer",
        max: "5",
        min: "1",
        default: "1",
      },
      {
        name: "size",
        label: "Size",
        type: "select",
        options: [
          ["256x256", "256x256"],
          ["512x512", "512x512"],
          ["1024x1024", "1024x1024"],
        ],
        default: "1024x1024",
      },
    ],
  },
  {
    id: "google-imagen",
    name: "Google Imagen",
    family: "image",
    desc: "Google's powerful text-to-image model.",
    params: [
      {
        name: "sampleCount",
        label: "Count",
        type: "integer",
        max: "5",
        min: "1",
        default: "1",
      },
      {
        name: "negativePrompt",
        label: "Negative Prompt",
        type: "string",
        default:
          "ugly, tiling, poorly drawn hands, poorly drawn feet, poorly drawn face, out of frame, extra limbs, disfigured, deformed, body out of frame, blurry, bad anatomy, blurred, watermark, grainy, signature, cut off, draft",
      },
    ],
  },
  {
    id: "theb-ai",
    name: "TheB.AI",
    family: "chat",
    desc: "Optimized conversation model, faster response, more natural and vivid language. Powered by OpenAI.",
    params: [
      {
        name: "temperature",
        label: "Temperature",
        type: "number",
        max: "2",
        min: "0",
        default: "1",
        precision: "0.01",
      },
      {
        name: "top_p",
        label: "Top P",
        type: "number",
        max: "1",
        min: "0",
        default: "1",
        precision: "0.01",
      },
      {
        name: "frequency_penalty",
        label: "Frequency penalty",
        type: "number",
        min: "-2",
        max: "2",
        default: "0",
        precision: "0.01",
      },
      {
        name: "presence_penalty",
        label: "Presence Penalty",
        type: "number",
        min: "-2",
        max: "2",
        default: "0",
        precision: "0.01",
      },
    ],
  },
  {
    id: "gpt-3.5-turbo",
    name: "GPT-3.5",
    family: "chat",
    desc: "Capable of solving most everyday problems or providing entertainment.",
    params: [
      {
        name: "temperature",
        label: "Temperature",
        type: "number",
        max: "2",
        min: "0",
        default: "1",
        precision: "0.01",
      },
      {
        name: "top_p",
        label: "Top P",
        type: "number",
        max: "1",
        min: "0",
        default: "1",
        precision: "0.01",
      },
      {
        name: "frequency_penalty",
        label: "Frequency penalty",
        type: "number",
        min: "-2",
        max: "2",
        default: "0",
        precision: "0.01",
      },
      {
        name: "presence_penalty",
        label: "Presence Penalty",
        type: "number",
        min: "-2",
        max: "2",
        default: "0",
        precision: "0.01",
      },
    ],
  },
  {
    id: "gpt-3.5-turbo-16k",
    name: "GPT-3.5-16K",
    family: "chat",
    desc: "Capable of solving most everyday problems or providing entertainment, with longer context.",
    params: [
      {
        name: "temperature",
        label: "Temperature",
        type: "number",
        max: "2",
        min: "0",
        default: "1",
        precision: "0.01",
      },
      {
        name: "top_p",
        label: "Top P",
        type: "number",
        max: "1",
        min: "0",
        default: "1",
        precision: "0.01",
      },
      {
        name: "frequency_penalty",
        label: "Frequency penalty",
        type: "number",
        min: "-2",
        max: "2",
        default: "0",
        precision: "0.01",
      },
      {
        name: "presence_penalty",
        label: "Presence Penalty",
        type: "number",
        min: "-2",
        max: "2",
        default: "0",
        precision: "0.01",
      },
    ],
  },
  {
    id: "gpt-4-turbo",
    name: "GPT-4 Turbo",
    family: "chat",
    desc: "OpenAI’s most advanced system, excellent performance on most questions and fast, with 128k context.",
    params: [
      {
        name: "temperature",
        label: "Temperature",
        type: "number",
        max: "2",
        min: "0",
        default: "1",
        precision: "0.01",
      },
      {
        name: "top_p",
        label: "Top P",
        type: "number",
        max: "1",
        min: "0",
        default: "1",
        precision: "0.01",
      },
      {
        name: "frequency_penalty",
        label: "Frequency penalty",
        type: "number",
        min: "-2",
        max: "2",
        default: "0",
        precision: "0.01",
      },
      {
        name: "presence_penalty",
        label: "Presence Penalty",
        type: "number",
        min: "-2",
        max: "2",
        default: "0",
        precision: "0.01",
      },
    ],
  },
  {
    id: "gpt-4-1106-preview",
    name: "GPT-4 Turbo",
    family: "chat",
    desc: "OpenAI’s most advanced system, excellent performance on most questions and fast, with 128k context.",
    params: [
      {
        name: "temperature",
        label: "Temperature",
        type: "number",
        max: "2",
        min: "0",
        default: "1",
        precision: "0.01",
      },
      {
        name: "top_p",
        label: "Top P",
        type: "number",
        max: "1",
        min: "0",
        default: "1",
        precision: "0.01",
      },
      {
        name: "frequency_penalty",
        label: "Frequency penalty",
        type: "number",
        min: "-2",
        max: "2",
        default: "0",
        precision: "0.01",
      },
      {
        name: "presence_penalty",
        label: "Presence Penalty",
        type: "number",
        min: "-2",
        max: "2",
        default: "0",
        precision: "0.01",
      },
    ],
  },
  {
    id: "gpt-4",
    name: "GPT-4",
    family: "chat",
    desc: "OpenAI’s most advanced system, excellent performance on most questions. Note that this model is more expensive.",
    params: [
      {
        name: "temperature",
        label: "Temperature",
        type: "number",
        max: "2",
        min: "0",
        default: "1",
        precision: "0.01",
      },
      {
        name: "top_p",
        label: "Top P",
        type: "number",
        max: "1",
        min: "0",
        default: "1",
        precision: "0.01",
      },
      {
        name: "frequency_penalty",
        label: "Frequency penalty",
        type: "number",
        min: "-2",
        max: "2",
        default: "0",
        precision: "0.01",
      },
      {
        name: "presence_penalty",
        label: "Presence Penalty",
        type: "number",
        min: "-2",
        max: "2",
        default: "0",
        precision: "0.01",
      },
    ],
  },
  {
    id: "gpt-4-32k",
    name: "GPT-4 32K",
    family: "chat",
    desc: "OpenAI’s most advanced system, excellent performance on most questions, especially long text processing. Note that this model is more expensive.",
    params: [
      {
        name: "temperature",
        label: "Temperature",
        type: "number",
        max: "2",
        min: "0",
        default: "1",
        precision: "0.01",
      },
      {
        name: "top_p",
        label: "Top P",
        type: "number",
        max: "1",
        min: "0",
        default: "1",
        precision: "0.01",
      },
      {
        name: "frequency_penalty",
        label: "Frequency penalty",
        type: "number",
        min: "-2",
        max: "2",
        default: "0",
        precision: "0.01",
      },
      {
        name: "presence_penalty",
        label: "Presence Penalty",
        type: "number",
        min: "-2",
        max: "2",
        default: "0",
        precision: "0.01",
      },
    ],
  },
  {
    id: "claude-2",
    name: "Claude 2",
    family: "chat",
    desc: "Anthropic's most powerful model, with 1M tokens Context, especially suitable for super long text processing.",
    params: [
      {
        name: "temperature",
        label: "Temperature",
        type: "number",
        max: "1",
        min: "0",
        default: "0",
        precision: "0.01",
      },
      {
        name: "top_p",
        label: "top_p",
        type: "number",
        min: "0",
        max: "1",
        default: "0.7",
        precision: "0.1",
      },
      {
        name: "top_k",
        label: "top_k",
        type: "integer",
        min: "0",
        max: "20",
        default: "5",
      },
    ],
  },
  {
    id: "claude-1",
    name: "Claude",
    family: "chat",
    desc: "Anthropic's powerful model, which excels at a wide range of tasks.",
    params: [
      {
        name: "temperature",
        label: "Temperature",
        type: "number",
        max: "1",
        min: "0",
        default: "0",
        precision: "0.01",
      },
      {
        name: "top_p",
        label: "top_p",
        type: "number",
        min: "0",
        max: "1",
        default: "0.7",
        precision: "0.1",
      },
      {
        name: "top_k",
        label: "top_k",
        type: "integer",
        min: "0",
        max: "20",
        default: "5",
      },
    ],
  },
  {
    id: "claude-1-100k",
    name: "Claude 100K",
    family: "chat",
    desc: "Anthropic's powerful model, with 1M tokens Context, especially suitable for super long text processing.",
    params: [
      {
        name: "temperature",
        label: "Temperature",
        type: "number",
        max: "1",
        min: "0",
        default: "0",
        precision: "0.01",
      },
      {
        name: "top_p",
        label: "top_p",
        type: "number",
        min: "0",
        max: "1",
        default: "0.7",
        precision: "0.1",
      },
      {
        name: "top_k",
        label: "top_k",
        type: "integer",
        min: "0",
        max: "20",
        default: "5",
      },
    ],
  },
  {
    id: "claude-instant-1",
    name: "Claude Instant",
    family: "chat",
    desc: "A faster, cheaper yet still very capable model, which can handle a range of tasks.",
    params: [
      {
        name: "temperature",
        label: "Temperature",
        type: "number",
        max: "1",
        min: "0",
        default: "0",
        precision: "0.01",
      },
      {
        name: "top_p",
        label: "top_p",
        type: "number",
        min: "0",
        max: "1",
        default: "0.7",
        precision: "0.1",
      },
      {
        name: "top_k",
        label: "top_k",
        type: "integer",
        min: "0",
        max: "20",
        default: "5",
      },
    ],
  },
  {
    id: "claude-instant-1-100k",
    name: "Claude Instant 100K",
    family: "chat",
    desc: "A faster, cheaper yet still very capable model, with 1M tokens Context, especially suitable for super long text processing.",
    params: [
      {
        name: "temperature",
        label: "Temperature",
        type: "number",
        max: "1",
        min: "0",
        default: "0",
        precision: "0.01",
      },
      {
        name: "top_p",
        label: "top_p",
        type: "number",
        min: "0",
        max: "1",
        default: "0.7",
        precision: "0.1",
      },
      {
        name: "top_k",
        label: "top_k",
        type: "integer",
        min: "0",
        max: "20",
        default: "5",
      },
    ],
  },
  {
    id: "gemini-pro",
    name: "Gemini Pro",
    family: "chat",
    desc: "Google's most advanced model, excellent performance in translation, text analysis, etc.",
    params: [
      {
        name: "temperature",
        label: "Temperature",
        type: "number",
        max: "2",
        min: "0",
        default: "1",
        precision: "0.01",
      },
      {
        name: "top_p",
        label: "Top P",
        type: "number",
        max: "1",
        min: "0",
        default: "1",
        precision: "0.01",
      },
      {
        name: "frequency_penalty",
        label: "Frequency penalty",
        type: "number",
        min: "-2",
        max: "2",
        default: "0",
        precision: "0.01",
      },
      {
        name: "presence_penalty",
        label: "Presence Penalty",
        type: "number",
        min: "-2",
        max: "2",
        default: "0",
        precision: "0.01",
      },
    ],
  },
  {
    id: "palm-2",
    name: "PaLM 2",
    family: "chat",
    desc: "Google's most advanced model, excellent performance in translation, text analysis, etc.",
    params: [
      {
        name: "temperature",
        label: "Temperature",
        type: "number",
        max: "1",
        min: "0",
        default: "0.8",
        precision: "0.1",
      },
      {
        name: "topP",
        label: "Top P",
        type: "number",
        max: "1",
        min: "0",
        default: "1",
        precision: "0.1",
      },
      {
        name: "topK",
        label: "Top K",
        type: "number",
        max: "40",
        min: "0",
        default: "40",
        precision: "0.1",
      },
    ],
  },
  {
    id: "palm-2-codey",
    name: "Codey",
    family: "chat",
    desc: "Based on PaLM 2, optimized for text to code generation.",
    params: [
      {
        name: "temperature",
        label: "Temperature",
        type: "number",
        max: "1",
        min: "0",
        default: "0.8",
        precision: "0.1",
      },
      {
        name: "topP",
        label: "Top P",
        type: "number",
        max: "1",
        min: "0",
        default: "1",
        precision: "0.1",
      },
      {
        name: "topK",
        label: "Top K",
        type: "number",
        max: "40",
        min: "0",
        default: "40",
        precision: "0.1",
      },
    ],
  },
  {
    id: "vicuna-13b-v1.5",
    name: "Vicuna v1.5 13B",
    family: "chat",
    desc: "Vicuna v1.5 13B is a chat assistant model fine-tuned on Llama 2 13B.",
    params: [
      {
        name: "temperature",
        label: "Temperature",
        type: "number",
        max: "3",
        min: "0",
        default: "0.7",
        precision: "0.01",
      },
      {
        name: "top_p",
        label: "Top P",
        type: "number",
        max: "3",
        min: "0",
        default: "0.7",
        precision: "0.1",
      },
      {
        name: "top_k",
        label: "Top K",
        type: "integer",
        max: "300",
        min: "0",
        default: "50",
      },
      {
        name: "repetition_penalty",
        label: "Repetition penalty",
        type: "number",
        min: "-2",
        max: "2",
        default: "1.2",
        precision: "0.1",
      },
    ],
  },
  {
    id: "llama-2-7b-chat",
    name: "Llama 2 7B",
    family: "chat",
    desc: "A large language model open sourced by Meta AI, with 7 billion parameters.",
    params: [
      {
        name: "temperature",
        label: "Temperature",
        type: "number",
        max: "3",
        min: "0",
        default: "0.7",
        precision: "0.01",
      },
      {
        name: "top_p",
        label: "Top P",
        type: "number",
        max: "3",
        min: "0",
        default: "0.7",
        precision: "0.1",
      },
      {
        name: "top_k",
        label: "Top K",
        type: "integer",
        max: "300",
        min: "0",
        default: "50",
      },
      {
        name: "repetition_penalty",
        label: "Repetition penalty",
        type: "number",
        min: "-2",
        max: "2",
        default: "1.2",
        precision: "0.1",
      },
    ],
  },
  {
    id: "llama-2-13b-chat",
    name: "Llama 2 13B",
    family: "chat",
    desc: "A large language model open sourced by Meta AI, with 7 billion parameters.",
    params: [
      {
        name: "temperature",
        label: "Temperature",
        type: "number",
        max: "3",
        min: "0",
        default: "0.7",
        precision: "0.01",
      },
      {
        name: "top_p",
        label: "Top P",
        type: "number",
        max: "3",
        min: "0",
        default: "0.7",
        precision: "0.1",
      },
      {
        name: "top_k",
        label: "Top K",
        type: "integer",
        max: "300",
        min: "0",
        default: "50",
      },
      {
        name: "repetition_penalty",
        label: "Repetition penalty",
        type: "number",
        min: "-2",
        max: "2",
        default: "1.2",
        precision: "0.1",
      },
    ],
  },
  {
    id: "llama-2-70b-chat",
    name: "Llama 2 70B",
    family: "chat",
    desc: "A large language model open sourced by Meta AI, with 70 billion parameters.",
    params: [
      {
        name: "temperature",
        label: "Temperature",
        type: "number",
        max: "3",
        min: "0",
        default: "0.7",
        precision: "0.01",
      },
      {
        name: "top_p",
        label: "Top P",
        type: "number",
        max: "3",
        min: "0",
        default: "0.7",
        precision: "0.1",
      },
      {
        name: "top_k",
        label: "Top K",
        type: "integer",
        max: "300",
        min: "0",
        default: "50",
      },
      {
        name: "repetition_penalty",
        label: "Repetition penalty",
        type: "number",
        min: "-2",
        max: "2",
        default: "1.2",
        precision: "0.1",
      },
    ],
  },
  {
    id: "code-llama-7b",
    name: "Code Llama 7B",
    family: "chat",
    desc: "Code Llama 7B is a family of large language models for code based on Llama 2.",
    params: [
      {
        name: "temperature",
        label: "Temperature",
        type: "number",
        max: "3",
        min: "0",
        default: "0.7",
        precision: "0.01",
      },
      {
        name: "top_p",
        label: "Top P",
        type: "number",
        max: "3",
        min: "0",
        default: "0.7",
        precision: "0.1",
      },
      {
        name: "top_k",
        label: "Top K",
        type: "integer",
        max: "300",
        min: "0",
        default: "50",
      },
      {
        name: "repetition_penalty",
        label: "Repetition penalty",
        type: "number",
        min: "-2",
        max: "2",
        default: "1.2",
        precision: "0.1",
      },
    ],
  },
  {
    id: "code-llama-13b",
    name: "Code Llama 13B",
    family: "chat",
    desc: "Code Llama 13B is a family of large language models for code based on Llama 2.",
    params: [
      {
        name: "temperature",
        label: "Temperature",
        type: "number",
        max: "3",
        min: "0",
        default: "0.7",
        precision: "0.01",
      },
      {
        name: "top_p",
        label: "Top P",
        type: "number",
        max: "3",
        min: "0",
        default: "0.7",
        precision: "0.1",
      },
      {
        name: "top_k",
        label: "Top K",
        type: "integer",
        max: "300",
        min: "0",
        default: "50",
      },
      {
        name: "repetition_penalty",
        label: "Repetition penalty",
        type: "number",
        min: "-2",
        max: "2",
        default: "1.2",
        precision: "0.1",
      },
    ],
  },
  {
    id: "code-llama-34b",
    name: "Code Llama 34B",
    family: "chat",
    desc: "Code Llama 34B is a family of large language models for code based on Llama 2",
    params: [
      {
        name: "temperature",
        label: "Temperature",
        type: "number",
        max: "3",
        min: "0",
        default: "0.7",
        precision: "0.01",
      },
      {
        name: "top_p",
        label: "Top P",
        type: "number",
        max: "3",
        min: "0",
        default: "0.7",
        precision: "0.1",
      },
      {
        name: "top_k",
        label: "Top K",
        type: "integer",
        max: "300",
        min: "0",
        default: "50",
      },
      {
        name: "repetition_penalty",
        label: "Repetition penalty",
        type: "number",
        min: "-2",
        max: "2",
        default: "1.2",
        precision: "0.1",
      },
    ],
  },
  {
    id: "qwen-7b-chat",
    name: "Qwen 7B",
    family: "chat",
    desc: "A large language model open sourced by Alibaba Cloud, with 7 billion parameters.",
    params: [
      {
        name: "temperature",
        label: "Temperature",
        type: "number",
        max: "3",
        min: "0",
        default: "0.7",
        precision: "0.01",
      },
      {
        name: "top_p",
        label: "Top P",
        type: "number",
        max: "3",
        min: "0",
        default: "0.7",
        precision: "0.1",
      },
      {
        name: "top_k",
        label: "Top K",
        type: "integer",
        max: "300",
        min: "0",
        default: "50",
      },
      {
        name: "repetition_penalty",
        label: "Repetition penalty",
        type: "number",
        min: "-2",
        max: "2",
        default: "1.2",
        precision: "0.1",
      },
    ],
  },
];
